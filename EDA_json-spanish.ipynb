{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/hu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw to /home/hu/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/omw.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import EDA\n",
    "from tqdm import tqdm\n",
    "from EDA import eda\n",
    "import random\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'relumbrar', 'resplandor', 'lucir', 'relucir', 'reflejar', 'resplandecer', 'brillo', 'esplendor', 'brillar', 'radiancia espectral'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "synonyms = set()\n",
    "word = 'shine'\n",
    "if wordnet.synsets(word):\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for l in syn.lemma_names('spa'):\n",
    "            synonym = l.replace('_', \" \").lower()\n",
    "            synonym = \"\".join([char for char in synonym if (char.isalpha() or char == ' ')])\n",
    "            synonyms.add(synonym)\n",
    "if word in synonyms:\n",
    "    synonyms.remove(word)\n",
    "print(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trim so that have desired number of augmented sentences',\n",
       " 'trim so that we have the desired number of want augmented sentences',\n",
       " 'trim so that we have the desired number of augmented sentences',\n",
       " 'and so trim so that we have the desired number of augmented sentences']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda('trim so that we have the desired number of augmented sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('./cleaned_labeled_data_v3.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIME</td>\n",
       "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
       "      <td>She left her husband. He killed their children...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "      <td>Of course it has a song.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
       "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
       "      <td>The actor gives Dems an ass-kicking for not fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
       "      <td>The \"Dietland\" actress said using the bags is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Morgan Freeman 'Devastated' That Sexual Harass...</td>\n",
       "      <td>\"It is not right to equate horrific incidents ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>What To Watch On Amazon Prime That’s New This ...</td>\n",
       "      <td>There's a great mini-series joining this week.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Mike Myers Reveals He'd 'Like To' Do A Fourth ...</td>\n",
       "      <td>Myer's kids may be pushing for a new \"Powers\" ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>What To Watch On Hulu That’s New This Week</td>\n",
       "      <td>You're getting a recent Academy Award-winning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Justin Timberlake Visits Texas School Shooting...</td>\n",
       "      <td>The pop star also wore a \"Santa Fe Strong\" shi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                           headline  \\\n",
       "0          CRIME  There Were 2 Mass Shootings In Texas Last Week...   \n",
       "1  ENTERTAINMENT  Will Smith Joins Diplo And Nicky Jam For The 2...   \n",
       "2  ENTERTAINMENT    Hugh Grant Marries For The First Time At Age 57   \n",
       "3  ENTERTAINMENT  Jim Carrey Blasts 'Castrato' Adam Schiff And D...   \n",
       "4  ENTERTAINMENT  Julianna Margulies Uses Donald Trump Poop Bags...   \n",
       "5  ENTERTAINMENT  Morgan Freeman 'Devastated' That Sexual Harass...   \n",
       "6  ENTERTAINMENT  What To Watch On Amazon Prime That’s New This ...   \n",
       "7  ENTERTAINMENT  Mike Myers Reveals He'd 'Like To' Do A Fourth ...   \n",
       "8  ENTERTAINMENT         What To Watch On Hulu That’s New This Week   \n",
       "9  ENTERTAINMENT  Justin Timberlake Visits Texas School Shooting...   \n",
       "\n",
       "                                         description  \n",
       "0  She left her husband. He killed their children...  \n",
       "1                           Of course it has a song.  \n",
       "2  The actor and his longtime girlfriend Anna Ebe...  \n",
       "3  The actor gives Dems an ass-kicking for not fi...  \n",
       "4  The \"Dietland\" actress said using the bags is ...  \n",
       "5  \"It is not right to equate horrific incidents ...  \n",
       "6     There's a great mini-series joining this week.  \n",
       "7  Myer's kids may be pushing for a new \"Powers\" ...  \n",
       "8  You're getting a recent Academy Award-winning ...  \n",
       "9  The pop star also wore a \"Santa Fe Strong\" shi...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = df['description']\n",
    "headline = df['headline']\n",
    "category = df['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dic = {}\n",
    "for idx,cate in enumerate(list(set(df['category']))):\n",
    "    category_dic[cate] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SPORTS': 0,\n",
       " 'WELLNESS': 1,\n",
       " 'TRAVEL': 2,\n",
       " 'DIVORCE': 3,\n",
       " 'ENVIRONMENT': 4,\n",
       " 'MEDIA': 5,\n",
       " 'WOMEN': 6,\n",
       " 'GROUPS VOICES': 7,\n",
       " 'RELIGION': 8,\n",
       " 'FOOD & DRINK': 9,\n",
       " 'CRIME': 10,\n",
       " 'WEDDINGS': 11,\n",
       " 'IMPACT': 12,\n",
       " 'SCIENCE & TECH': 13,\n",
       " 'WORLD NEWS': 14,\n",
       " 'WEIRD NEWS': 15,\n",
       " 'STYLE & BEAUTY': 16,\n",
       " 'HOME & LIVING': 17,\n",
       " 'ARTS & CULTURE': 18,\n",
       " 'MISCELLANEOUS': 19,\n",
       " 'ENTERTAINMENT': 20,\n",
       " 'COMEDY': 21,\n",
       " 'EDUCATION': 22,\n",
       " 'PARENTING': 23,\n",
       " 'POLITICS': 24,\n",
       " 'BUSINESS & FINANCES': 25}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPORTS:3703\n",
      "WELLNESS:22639\n",
      "TRAVEL:9218\n",
      "DIVORCE:3406\n",
      "ENVIRONMENT:3309\n",
      "MEDIA:2174\n",
      "WOMEN:2871\n",
      "GROUPS VOICES:10242\n",
      "RELIGION:1798\n",
      "FOOD & DRINK:6816\n",
      "CRIME:2579\n",
      "WEDDINGS:3632\n",
      "IMPACT:3032\n",
      "SCIENCE & TECH:3534\n",
      "WORLD NEWS:6842\n",
      "WEIRD NEWS:1679\n",
      "STYLE & BEAUTY:10541\n",
      "HOME & LIVING:3946\n",
      "ARTS & CULTURE:3095\n",
      "MISCELLANEOUS:1962\n",
      "ENTERTAINMENT:11626\n",
      "COMEDY:3734\n",
      "EDUCATION:1784\n",
      "PARENTING:11804\n",
      "POLITICS:27829\n",
      "BUSINESS & FINANCES:6654\n",
      "total: 170449\n",
      "max_cate:27829\n",
      "min_cate:1679\n",
      "[3703, 22639, 9218, 3406, 3309, 2174, 2871, 10242, 1798, 6816, 2579, 3632, 3032, 3534, 6842, 1679, 10541, 3946, 3095, 1962, 11626, 3734, 1784, 11804, 27829, 6654]\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "maxl,minl = 0,100000\n",
    "dic_count = []\n",
    "for ca in category_dic.keys():\n",
    "    cur_len = len([i for i in category if i==ca])\n",
    "    print('{}:{}'.format(ca,cur_len))\n",
    "    maxl,minl = max(maxl,cur_len),min(minl,cur_len)\n",
    "    dic_count.append(cur_len)\n",
    "    total += cur_len\n",
    "print('total:',total)\n",
    "print('max_cate:{}\\nmin_cate:{}'.format(maxl,minl))\n",
    "print(dic_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find a proper increase num_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3703 7.081534722366481\n",
      "1 22639 1.158307481643318\n",
      "2 9218 2.844751906804413\n",
      "3 3406 7.69903789692398\n",
      "4 3309 7.924727433340308\n",
      "5 2174 12.0620621328993\n",
      "6 2871 9.133724513034858\n",
      "7 10242 2.5603322668349033\n",
      "8 1798 14.58449559339437\n",
      "9 6816 3.8472598410978693\n",
      "10 2579 10.167864706057804\n",
      "11 3632 7.219967807522873\n",
      "12 3032 8.64872133143901\n",
      "13 3534 7.420181968569066\n",
      "14 6842 3.832640028781508\n",
      "15 1679 15.618179319191828\n",
      "16 10541 2.4877073405676007\n",
      "17 3946 6.645444266833015\n",
      "18 3095 8.472673045855599\n",
      "19 1962 13.365404218615229\n",
      "20 11626 2.2555412933875\n",
      "21 3734 7.022743191463063\n",
      "22 1784 14.698947913073473\n",
      "23 11804 2.221528556160884\n",
      "24 27829 0.942287652338319\n",
      "25 6654 3.9409262213590437\n"
     ]
    }
   ],
   "source": [
    "for ca in category_dic.keys():\n",
    "    p = 4/(dic_count[category_dic[ca]]/(sum(dic_count)/len(dic_count)))\n",
    "    print(category_dic[ca],dic_count[category_dic[ca]],p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "augumented_news = [[],[],[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170449it [02:02, 1389.24it/s]\n"
     ]
    }
   ],
   "source": [
    "for cate,head,cont in tqdm(zip(category,headline,content)):\n",
    "    if max(len(head),len(cont)>10):\n",
    "        p = 4/(dic_count[category_dic[ca]]/(sum(dic_count)/len(dic_count)))\n",
    "        if len(head)>len(cont):\n",
    "            new_heads = eda(head,num_aug=max(6,int(p)))\n",
    "            for new in new_heads:\n",
    "                augumented_news[0].append(cate)\n",
    "                augumented_news[1].append(new)\n",
    "                augumented_news[2].append(cont)\n",
    "        else:\n",
    "            new_conts = eda(cont)\n",
    "            for new in new_conts:\n",
    "                augumented_news[0].append(cate)\n",
    "                augumented_news[1].append(head)\n",
    "                augumented_news[2].append(new)\n",
    "    else:\n",
    "        augumented_news[0].append(cate)\n",
    "        augumented_news[1].append(head)\n",
    "        augumented_news[2].append(cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "851194"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(augumented_news[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPORTS:19267\n",
      "WELLNESS:108798\n",
      "TRAVEL:44678\n",
      "DIVORCE:15915\n",
      "ENVIRONMENT:15951\n",
      "MEDIA:11181\n",
      "WOMEN:14564\n",
      "GROUPS VOICES:51660\n",
      "RELIGION:9008\n",
      "FOOD & DRINK:34890\n",
      "CRIME:13016\n",
      "WEDDINGS:16817\n",
      "IMPACT:15105\n",
      "SCIENCE & TECH:17268\n",
      "WORLD NEWS:34647\n",
      "WEIRD NEWS:9186\n",
      "STYLE & BEAUTY:50058\n",
      "HOME & LIVING:19701\n",
      "ARTS & CULTURE:15529\n",
      "MISCELLANEOUS:10161\n",
      "ENTERTAINMENT:61886\n",
      "COMEDY:19655\n",
      "EDUCATION:8903\n",
      "PARENTING:57463\n",
      "POLITICS:143750\n",
      "BUSINESS & FINANCES:32137\n",
      "total: 851194\n",
      "max_cate:143750\n",
      "min_cate:8903\n",
      "[19267, 108798, 44678, 15915, 15951, 11181, 14564, 51660, 9008, 34890, 13016, 16817, 15105, 17268, 34647, 9186, 50058, 19701, 15529, 10161, 61886, 19655, 8903, 57463, 143750, 32137]\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "maxl,minl = 0,100000\n",
    "dic_count = []\n",
    "for ca in category_dic.keys():\n",
    "    cur_len = len([i for i in augumented_news[0] if i==ca])\n",
    "    print('{}:{}'.format(ca,cur_len))\n",
    "    maxl,minl = max(maxl,cur_len),min(minl,cur_len)\n",
    "    dic_count.append(cur_len)\n",
    "    total += cur_len\n",
    "print('total:',total)\n",
    "print('max_cate:{}\\nmin_cate:{}'.format(maxl,minl))\n",
    "print(dic_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_idx = [i for i in range(0,len(augumented_news[0]))]\n",
    "random.shuffle(shuffle_idx)\n",
    "shuffled_data = [[],[],[]]\n",
    "for idx in shuffle_idx:\n",
    "    shuffled_data[0].append(augumented_news[0][idx])\n",
    "    shuffled_data[1].append(augumented_news[1][idx])\n",
    "    shuffled_data[2].append(augumented_news[2][idx])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_df = {\n",
    "    'category':shuffled_data[0],\n",
    "    'head':shuffled_data[1],\n",
    "    'content':shuffled_data[2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_df = pd.DataFrame(data=augmented_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       WEIRD NEWS\n",
       "1     FOOD & DRINK\n",
       "2           SPORTS\n",
       "3         WEDDINGS\n",
       "4    MISCELLANEOUS\n",
       "5          DIVORCE\n",
       "6           COMEDY\n",
       "7    GROUPS VOICES\n",
       "8     FOOD & DRINK\n",
       "9       WEIRD NEWS\n",
       "Name: category, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_df['category'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_df.to_json('./augmented_labeled_news.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
